{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ChatterCheetah Data Analysis\n",
    "\n",
    "This notebook provides comprehensive data analysis for the ChatterCheetah platform.\n",
    "\n",
    "**Designed for:** Vertex AI Workbench (GCP)\n",
    "\n",
    "## What This Notebook Covers\n",
    "\n",
    "1. **Tenant Overview** - Active tenants and their usage\n",
    "2. **Conversation Analytics** - Volume, channels, timing patterns\n",
    "3. **Message Analysis** - Response patterns, content metrics\n",
    "4. **Lead Capture Performance** - Conversion rates, contact info quality\n",
    "5. **Channel Analysis** - Web vs SMS vs Voice performance\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before running, ensure:\n",
    "1. Environment variables are set (same as main app)\n",
    "2. Database connectivity is available (Cloud SQL via private networking)\n",
    "3. Required packages are installed: `uv add pandas matplotlib seaborn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Data analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Async support for notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import asyncio\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ“ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database imports\n",
    "from sqlalchemy import text, select, func\n",
    "from sqlalchemy.ext.asyncio import AsyncSession\n",
    "\n",
    "# App imports\n",
    "from notebooks.utils import get_db_session, setup_tenant_context\n",
    "from app.persistence.models.tenant import Tenant, User\n",
    "from app.persistence.models.conversation import Conversation, Message\n",
    "from app.persistence.models.lead import Lead\n",
    "from app.persistence.database import AsyncSessionLocal\n",
    "\n",
    "print(\"âœ“ Database modules loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helper-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for async database queries\n",
    "\n",
    "async def fetch_all_tenants() -> pd.DataFrame:\n",
    "    \"\"\"Fetch all tenants as DataFrame.\"\"\"\n",
    "    async with get_db_session() as session:\n",
    "        result = await session.execute(select(Tenant))\n",
    "        tenants = result.scalars().all()\n",
    "        return pd.DataFrame([\n",
    "            {\n",
    "                'id': t.id,\n",
    "                'name': t.name,\n",
    "                'subdomain': t.subdomain,\n",
    "                'is_active': t.is_active,\n",
    "                'created_at': t.created_at\n",
    "            }\n",
    "            for t in tenants\n",
    "        ])\n",
    "\n",
    "async def fetch_all_conversations() -> pd.DataFrame:\n",
    "    \"\"\"Fetch all conversations as DataFrame.\"\"\"\n",
    "    async with get_db_session() as session:\n",
    "        result = await session.execute(select(Conversation))\n",
    "        conversations = result.scalars().all()\n",
    "        return pd.DataFrame([\n",
    "            {\n",
    "                'id': c.id,\n",
    "                'tenant_id': c.tenant_id,\n",
    "                'channel': c.channel,\n",
    "                'external_id': c.external_id,\n",
    "                'created_at': c.created_at,\n",
    "                'updated_at': c.updated_at\n",
    "            }\n",
    "            for c in conversations\n",
    "        ])\n",
    "\n",
    "async def fetch_all_messages() -> pd.DataFrame:\n",
    "    \"\"\"Fetch all messages as DataFrame.\"\"\"\n",
    "    async with get_db_session() as session:\n",
    "        result = await session.execute(select(Message))\n",
    "        messages = result.scalars().all()\n",
    "        return pd.DataFrame([\n",
    "            {\n",
    "                'id': m.id,\n",
    "                'conversation_id': m.conversation_id,\n",
    "                'role': m.role,\n",
    "                'content': m.content,\n",
    "                'content_length': len(m.content) if m.content else 0,\n",
    "                'sequence_number': m.sequence_number,\n",
    "                'created_at': m.created_at\n",
    "            }\n",
    "            for m in messages\n",
    "        ])\n",
    "\n",
    "async def fetch_all_leads() -> pd.DataFrame:\n",
    "    \"\"\"Fetch all leads as DataFrame.\"\"\"\n",
    "    async with get_db_session() as session:\n",
    "        result = await session.execute(select(Lead))\n",
    "        leads = result.scalars().all()\n",
    "        return pd.DataFrame([\n",
    "            {\n",
    "                'id': l.id,\n",
    "                'tenant_id': l.tenant_id,\n",
    "                'conversation_id': l.conversation_id,\n",
    "                'email': l.email,\n",
    "                'phone': l.phone,\n",
    "                'name': l.name,\n",
    "                'extra_data': l.extra_data,\n",
    "                'has_email': l.email is not None,\n",
    "                'has_phone': l.phone is not None,\n",
    "                'has_name': l.name is not None,\n",
    "                'created_at': l.created_at\n",
    "            }\n",
    "            for l in leads\n",
    "        ])\n",
    "\n",
    "def run_async(coro):\n",
    "    \"\"\"Helper to run async coroutines in notebook.\"\"\"\n",
    "    return asyncio.get_event_loop().run_until_complete(coro)\n",
    "\n",
    "print(\"âœ“ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data from database\n",
    "print(\"Loading data from database...\")\n",
    "\n",
    "df_tenants = run_async(fetch_all_tenants())\n",
    "df_conversations = run_async(fetch_all_conversations())\n",
    "df_messages = run_async(fetch_all_messages())\n",
    "df_leads = run_async(fetch_all_leads())\n",
    "\n",
    "print(f\"\\nâœ“ Data loaded:\")\n",
    "print(f\"  - Tenants: {len(df_tenants):,}\")\n",
    "print(f\"  - Conversations: {len(df_conversations):,}\")\n",
    "print(f\"  - Messages: {len(df_messages):,}\")\n",
    "print(f\"  - Leads: {len(df_leads):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tenant-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Tenant Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tenant-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenant Summary Statistics\n",
    "if len(df_tenants) > 0:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TENANT SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total Tenants: {len(df_tenants)}\")\n",
    "    print(f\"Active Tenants: {df_tenants['is_active'].sum()}\")\n",
    "    print(f\"Inactive Tenants: {(~df_tenants['is_active']).sum()}\")\n",
    "    print()\n",
    "    \n",
    "    # Join with conversation counts\n",
    "    if len(df_conversations) > 0:\n",
    "        conv_counts = df_conversations.groupby('tenant_id').size().reset_index(name='conversation_count')\n",
    "        lead_counts = df_leads.groupby('tenant_id').size().reset_index(name='lead_count') if len(df_leads) > 0 else pd.DataFrame({'tenant_id': [], 'lead_count': []})\n",
    "        \n",
    "        tenant_stats = df_tenants.merge(conv_counts, left_on='id', right_on='tenant_id', how='left')\n",
    "        tenant_stats = tenant_stats.merge(lead_counts, left_on='id', right_on='tenant_id', how='left', suffixes=('', '_lead'))\n",
    "        tenant_stats['conversation_count'] = tenant_stats['conversation_count'].fillna(0).astype(int)\n",
    "        tenant_stats['lead_count'] = tenant_stats['lead_count'].fillna(0).astype(int)\n",
    "        \n",
    "        display_cols = ['name', 'subdomain', 'is_active', 'conversation_count', 'lead_count', 'created_at']\n",
    "        print(tenant_stats[display_cols].to_string(index=False))\n",
    "else:\n",
    "    print(\"No tenants found in database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tenant-activity-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenant Activity Over Time\n",
    "if len(df_conversations) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Conversations per tenant\n",
    "    conv_by_tenant = df_conversations.groupby('tenant_id').size().sort_values(ascending=True)\n",
    "    if len(conv_by_tenant) > 0:\n",
    "        tenant_names = df_tenants.set_index('id')['name'].to_dict()\n",
    "        conv_by_tenant.index = conv_by_tenant.index.map(lambda x: tenant_names.get(x, f'Tenant {x}'))\n",
    "        conv_by_tenant.plot(kind='barh', ax=axes[0], color='steelblue')\n",
    "        axes[0].set_xlabel('Number of Conversations')\n",
    "        axes[0].set_ylabel('Tenant')\n",
    "        axes[0].set_title('Conversations by Tenant')\n",
    "    \n",
    "    # Conversations over time\n",
    "    df_conversations['date'] = pd.to_datetime(df_conversations['created_at']).dt.date\n",
    "    daily_convs = df_conversations.groupby('date').size()\n",
    "    if len(daily_convs) > 0:\n",
    "        daily_convs.plot(ax=axes[1], color='green', linewidth=2)\n",
    "        axes[1].set_xlabel('Date')\n",
    "        axes[1].set_ylabel('Conversations')\n",
    "        axes[1].set_title('Daily Conversation Volume')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No conversations to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conversation-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Conversation Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conversation-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation Statistics\n",
    "if len(df_conversations) > 0:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"CONVERSATION SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total Conversations: {len(df_conversations):,}\")\n",
    "    \n",
    "    # Channel breakdown\n",
    "    print(\"\\nBy Channel:\")\n",
    "    channel_counts = df_conversations['channel'].value_counts()\n",
    "    for channel, count in channel_counts.items():\n",
    "        pct = (count / len(df_conversations)) * 100\n",
    "        print(f\"  {channel}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Time-based metrics\n",
    "    if 'created_at' in df_conversations.columns and len(df_conversations) > 0:\n",
    "        df_conversations['hour'] = pd.to_datetime(df_conversations['created_at']).dt.hour\n",
    "        df_conversations['day_of_week'] = pd.to_datetime(df_conversations['created_at']).dt.day_name()\n",
    "        \n",
    "        print(\"\\nBusiest Hours (top 5):\")\n",
    "        hour_counts = df_conversations['hour'].value_counts().head(5)\n",
    "        for hour, count in hour_counts.items():\n",
    "            print(f\"  {hour:02d}:00 - {count:,} conversations\")\n",
    "        \n",
    "        print(\"\\nBusiest Days:\")\n",
    "        day_counts = df_conversations['day_of_week'].value_counts()\n",
    "        for day, count in day_counts.items():\n",
    "            print(f\"  {day}: {count:,}\")\n",
    "else:\n",
    "    print(\"No conversations found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conversation-charts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation Visualizations\n",
    "if len(df_conversations) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Channel distribution\n",
    "    channel_counts = df_conversations['channel'].value_counts()\n",
    "    colors = sns.color_palette('husl', len(channel_counts))\n",
    "    axes[0, 0].pie(channel_counts.values, labels=channel_counts.index, autopct='%1.1f%%', colors=colors)\n",
    "    axes[0, 0].set_title('Conversations by Channel')\n",
    "    \n",
    "    # Hourly distribution\n",
    "    if 'hour' in df_conversations.columns:\n",
    "        hourly = df_conversations['hour'].value_counts().sort_index()\n",
    "        axes[0, 1].bar(hourly.index, hourly.values, color='teal', alpha=0.7)\n",
    "        axes[0, 1].set_xlabel('Hour of Day')\n",
    "        axes[0, 1].set_ylabel('Conversations')\n",
    "        axes[0, 1].set_title('Conversations by Hour')\n",
    "        axes[0, 1].set_xticks(range(0, 24, 2))\n",
    "    \n",
    "    # Day of week distribution\n",
    "    if 'day_of_week' in df_conversations.columns:\n",
    "        day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "        day_counts = df_conversations['day_of_week'].value_counts().reindex(day_order).fillna(0)\n",
    "        axes[1, 0].bar(day_counts.index, day_counts.values, color='coral', alpha=0.7)\n",
    "        axes[1, 0].set_xlabel('Day of Week')\n",
    "        axes[1, 0].set_ylabel('Conversations')\n",
    "        axes[1, 0].set_title('Conversations by Day of Week')\n",
    "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Conversation duration (updated_at - created_at)\n",
    "    df_conversations['duration_minutes'] = (\n",
    "        pd.to_datetime(df_conversations['updated_at']) - \n",
    "        pd.to_datetime(df_conversations['created_at'])\n",
    "    ).dt.total_seconds() / 60\n",
    "    \n",
    "    # Filter reasonable durations (< 1 day)\n",
    "    reasonable_durations = df_conversations[df_conversations['duration_minutes'] < 1440]['duration_minutes']\n",
    "    if len(reasonable_durations) > 0:\n",
    "        axes[1, 1].hist(reasonable_durations, bins=30, color='purple', alpha=0.7, edgecolor='black')\n",
    "        axes[1, 1].set_xlabel('Duration (minutes)')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('Conversation Duration Distribution')\n",
    "        axes[1, 1].axvline(reasonable_durations.median(), color='red', linestyle='--', label=f'Median: {reasonable_durations.median():.1f} min')\n",
    "        axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No conversations to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "message-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Message Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "message-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message Statistics\n",
    "if len(df_messages) > 0:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"MESSAGE SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total Messages: {len(df_messages):,}\")\n",
    "    \n",
    "    # Role breakdown\n",
    "    print(\"\\nBy Role:\")\n",
    "    role_counts = df_messages['role'].value_counts()\n",
    "    for role, count in role_counts.items():\n",
    "        pct = (count / len(df_messages)) * 100\n",
    "        print(f\"  {role}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Messages per conversation\n",
    "    msgs_per_conv = df_messages.groupby('conversation_id').size()\n",
    "    print(f\"\\nMessages per Conversation:\")\n",
    "    print(f\"  Average: {msgs_per_conv.mean():.1f}\")\n",
    "    print(f\"  Median: {msgs_per_conv.median():.1f}\")\n",
    "    print(f\"  Min: {msgs_per_conv.min()}\")\n",
    "    print(f\"  Max: {msgs_per_conv.max()}\")\n",
    "    \n",
    "    # Content length stats\n",
    "    print(f\"\\nContent Length (characters):\")\n",
    "    for role in df_messages['role'].unique():\n",
    "        role_msgs = df_messages[df_messages['role'] == role]\n",
    "        print(f\"  {role}:\")\n",
    "        print(f\"    Average: {role_msgs['content_length'].mean():.0f}\")\n",
    "        print(f\"    Median: {role_msgs['content_length'].median():.0f}\")\n",
    "else:\n",
    "    print(\"No messages found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "message-charts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Message Visualizations\n",
    "if len(df_messages) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Role distribution\n",
    "    role_counts = df_messages['role'].value_counts()\n",
    "    colors = {'user': '#3498db', 'assistant': '#2ecc71', 'system': '#9b59b6'}\n",
    "    role_colors = [colors.get(r, 'gray') for r in role_counts.index]\n",
    "    axes[0, 0].bar(role_counts.index, role_counts.values, color=role_colors)\n",
    "    axes[0, 0].set_xlabel('Role')\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    axes[0, 0].set_title('Messages by Role')\n",
    "    \n",
    "    # Messages per conversation histogram\n",
    "    msgs_per_conv = df_messages.groupby('conversation_id').size()\n",
    "    axes[0, 1].hist(msgs_per_conv, bins=20, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    axes[0, 1].set_xlabel('Messages per Conversation')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Distribution of Conversation Length')\n",
    "    axes[0, 1].axvline(msgs_per_conv.mean(), color='red', linestyle='--', label=f'Mean: {msgs_per_conv.mean():.1f}')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Content length by role\n",
    "    df_messages.boxplot(column='content_length', by='role', ax=axes[1, 0])\n",
    "    axes[1, 0].set_xlabel('Role')\n",
    "    axes[1, 0].set_ylabel('Content Length (characters)')\n",
    "    axes[1, 0].set_title('Message Length by Role')\n",
    "    plt.suptitle('')  # Remove automatic title\n",
    "    \n",
    "    # Response time analysis (time between messages)\n",
    "    df_messages_sorted = df_messages.sort_values(['conversation_id', 'sequence_number'])\n",
    "    df_messages_sorted['prev_created_at'] = df_messages_sorted.groupby('conversation_id')['created_at'].shift(1)\n",
    "    df_messages_sorted['response_time_seconds'] = (\n",
    "        pd.to_datetime(df_messages_sorted['created_at']) - \n",
    "        pd.to_datetime(df_messages_sorted['prev_created_at'])\n",
    "    ).dt.total_seconds()\n",
    "    \n",
    "    # Filter assistant responses (response to user)\n",
    "    assistant_responses = df_messages_sorted[\n",
    "        (df_messages_sorted['role'] == 'assistant') & \n",
    "        (df_messages_sorted['response_time_seconds'] > 0) &\n",
    "        (df_messages_sorted['response_time_seconds'] < 60)  # Under 1 minute\n",
    "    ]\n",
    "    \n",
    "    if len(assistant_responses) > 0:\n",
    "        axes[1, 1].hist(assistant_responses['response_time_seconds'], bins=30, color='green', alpha=0.7, edgecolor='black')\n",
    "        axes[1, 1].set_xlabel('Response Time (seconds)')\n",
    "        axes[1, 1].set_ylabel('Frequency')\n",
    "        axes[1, 1].set_title('AI Response Time Distribution')\n",
    "        axes[1, 1].axvline(assistant_responses['response_time_seconds'].median(), color='red', linestyle='--', \n",
    "                          label=f'Median: {assistant_responses[\"response_time_seconds\"].median():.2f}s')\n",
    "        axes[1, 1].legend()\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Insufficient response time data', ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No messages to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lead-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Lead Capture Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lead-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead Statistics\n",
    "if len(df_leads) > 0:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"LEAD CAPTURE SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total Leads: {len(df_leads):,}\")\n",
    "    \n",
    "    # Conversion rate (leads with conversations)\n",
    "    if len(df_conversations) > 0:\n",
    "        leads_with_conv = df_leads[df_leads['conversation_id'].notna()]\n",
    "        print(f\"Leads with Conversations: {len(leads_with_conv):,}\")\n",
    "        conv_rate = (len(df_leads) / len(df_conversations)) * 100 if len(df_conversations) > 0 else 0\n",
    "        print(f\"Lead Capture Rate: {conv_rate:.1f}%\")\n",
    "    \n",
    "    # Contact info quality\n",
    "    print(\"\\nContact Information Quality:\")\n",
    "    print(f\"  Has Email: {df_leads['has_email'].sum():,} ({(df_leads['has_email'].sum()/len(df_leads))*100:.1f}%)\")\n",
    "    print(f\"  Has Phone: {df_leads['has_phone'].sum():,} ({(df_leads['has_phone'].sum()/len(df_leads))*100:.1f}%)\")\n",
    "    print(f\"  Has Name: {df_leads['has_name'].sum():,} ({(df_leads['has_name'].sum()/len(df_leads))*100:.1f}%)\")\n",
    "    \n",
    "    # Complete leads (all info)\n",
    "    complete_leads = df_leads[df_leads['has_email'] & df_leads['has_phone'] & df_leads['has_name']]\n",
    "    print(f\"  Complete (all fields): {len(complete_leads):,} ({(len(complete_leads)/len(df_leads))*100:.1f}%)\")\n",
    "    \n",
    "    # Extra data analysis (Zapier integration)\n",
    "    leads_with_extra = df_leads[df_leads['extra_data'].notna()]\n",
    "    print(f\"\\nLeads with Extra Data (Zapier): {len(leads_with_extra):,}\")\n",
    "    \n",
    "    # Leads by tenant\n",
    "    print(\"\\nLeads by Tenant:\")\n",
    "    lead_by_tenant = df_leads.groupby('tenant_id').size().sort_values(ascending=False)\n",
    "    tenant_names = df_tenants.set_index('id')['name'].to_dict()\n",
    "    for tenant_id, count in lead_by_tenant.items():\n",
    "        tenant_name = tenant_names.get(tenant_id, f'Tenant {tenant_id}')\n",
    "        print(f\"  {tenant_name}: {count:,}\")\n",
    "else:\n",
    "    print(\"No leads found.\")\n",
    "    \n",
    "    if len(df_conversations) > 0:\n",
    "        print(f\"\\n(Total conversations: {len(df_conversations):,} - no leads captured yet)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lead-charts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lead Visualizations\n",
    "if len(df_leads) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Contact info breakdown\n",
    "    contact_data = {\n",
    "        'Email': df_leads['has_email'].sum(),\n",
    "        'Phone': df_leads['has_phone'].sum(),\n",
    "        'Name': df_leads['has_name'].sum()\n",
    "    }\n",
    "    axes[0, 0].bar(contact_data.keys(), contact_data.values(), color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "    axes[0, 0].set_ylabel('Count')\n",
    "    axes[0, 0].set_title('Lead Contact Information Availability')\n",
    "    axes[0, 0].axhline(len(df_leads), color='gray', linestyle='--', label=f'Total Leads: {len(df_leads)}')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Leads over time\n",
    "    df_leads['date'] = pd.to_datetime(df_leads['created_at']).dt.date\n",
    "    daily_leads = df_leads.groupby('date').size()\n",
    "    if len(daily_leads) > 0:\n",
    "        daily_leads.plot(ax=axes[0, 1], color='orange', linewidth=2, marker='o', markersize=4)\n",
    "        axes[0, 1].set_xlabel('Date')\n",
    "        axes[0, 1].set_ylabel('Leads')\n",
    "        axes[0, 1].set_title('Daily Lead Capture')\n",
    "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Leads by tenant\n",
    "    lead_by_tenant = df_leads.groupby('tenant_id').size().sort_values(ascending=True)\n",
    "    tenant_names = df_tenants.set_index('id')['name'].to_dict()\n",
    "    lead_by_tenant.index = lead_by_tenant.index.map(lambda x: tenant_names.get(x, f'Tenant {x}'))\n",
    "    lead_by_tenant.plot(kind='barh', ax=axes[1, 0], color='purple')\n",
    "    axes[1, 0].set_xlabel('Number of Leads')\n",
    "    axes[1, 0].set_ylabel('Tenant')\n",
    "    axes[1, 0].set_title('Leads by Tenant')\n",
    "    \n",
    "    # Lead quality distribution\n",
    "    df_leads['quality_score'] = df_leads['has_email'].astype(int) + df_leads['has_phone'].astype(int) + df_leads['has_name'].astype(int)\n",
    "    quality_dist = df_leads['quality_score'].value_counts().sort_index()\n",
    "    quality_labels = {0: 'None', 1: 'One field', 2: 'Two fields', 3: 'Complete'}\n",
    "    quality_dist.index = quality_dist.index.map(lambda x: quality_labels.get(x, str(x)))\n",
    "    axes[1, 1].bar(quality_dist.index, quality_dist.values, color=['#e74c3c', '#f39c12', '#3498db', '#2ecc71'][:len(quality_dist)])\n",
    "    axes[1, 1].set_xlabel('Lead Quality')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].set_title('Lead Quality Distribution')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No leads to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "channel-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Channel Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "channel-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Performance Comparison\n",
    "if len(df_conversations) > 0 and len(df_messages) > 0:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"CHANNEL PERFORMANCE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Merge conversations with messages\n",
    "    conv_msg_counts = df_messages.groupby('conversation_id').size().reset_index(name='msg_count')\n",
    "    conv_analysis = df_conversations.merge(conv_msg_counts, left_on='id', right_on='conversation_id', how='left')\n",
    "    conv_analysis['msg_count'] = conv_analysis['msg_count'].fillna(0)\n",
    "    \n",
    "    # Stats by channel\n",
    "    for channel in conv_analysis['channel'].unique():\n",
    "        channel_data = conv_analysis[conv_analysis['channel'] == channel]\n",
    "        print(f\"\\n{channel.upper()}:\")\n",
    "        print(f\"  Conversations: {len(channel_data):,}\")\n",
    "        print(f\"  Avg Messages/Conv: {channel_data['msg_count'].mean():.1f}\")\n",
    "        \n",
    "        # Lead conversion for channel\n",
    "        if len(df_leads) > 0:\n",
    "            channel_conv_ids = set(channel_data['id'])\n",
    "            channel_leads = df_leads[df_leads['conversation_id'].isin(channel_conv_ids)]\n",
    "            lead_rate = (len(channel_leads) / len(channel_data)) * 100 if len(channel_data) > 0 else 0\n",
    "            print(f\"  Leads: {len(channel_leads):,}\")\n",
    "            print(f\"  Lead Capture Rate: {lead_rate:.1f}%\")\n",
    "        \n",
    "        # Duration stats\n",
    "        if 'duration_minutes' in channel_data.columns:\n",
    "            print(f\"  Avg Duration: {channel_data['duration_minutes'].mean():.1f} min\")\n",
    "else:\n",
    "    print(\"Insufficient data for channel analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "channel-charts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel Comparison Charts\n",
    "if len(df_conversations) > 0 and len(df_messages) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Merge for analysis\n",
    "    conv_msg_counts = df_messages.groupby('conversation_id').size().reset_index(name='msg_count')\n",
    "    conv_analysis = df_conversations.merge(conv_msg_counts, left_on='id', right_on='conversation_id', how='left')\n",
    "    \n",
    "    # Messages per conversation by channel\n",
    "    channel_msg_avg = conv_analysis.groupby('channel')['msg_count'].mean()\n",
    "    axes[0].bar(channel_msg_avg.index, channel_msg_avg.values, color=sns.color_palette('husl', len(channel_msg_avg)))\n",
    "    axes[0].set_xlabel('Channel')\n",
    "    axes[0].set_ylabel('Avg Messages per Conversation')\n",
    "    axes[0].set_title('Engagement by Channel')\n",
    "    \n",
    "    # Duration by channel\n",
    "    if 'duration_minutes' in conv_analysis.columns:\n",
    "        channel_duration = conv_analysis.groupby('channel')['duration_minutes'].mean()\n",
    "        axes[1].bar(channel_duration.index, channel_duration.values, color=sns.color_palette('husl', len(channel_duration)))\n",
    "        axes[1].set_xlabel('Channel')\n",
    "        axes[1].set_ylabel('Avg Duration (minutes)')\n",
    "        axes[1].set_title('Conversation Duration by Channel')\n",
    "    \n",
    "    # Lead capture rate by channel\n",
    "    if len(df_leads) > 0:\n",
    "        lead_rates = {}\n",
    "        for channel in conv_analysis['channel'].unique():\n",
    "            channel_convs = conv_analysis[conv_analysis['channel'] == channel]\n",
    "            channel_conv_ids = set(channel_convs['id'])\n",
    "            channel_leads = df_leads[df_leads['conversation_id'].isin(channel_conv_ids)]\n",
    "            lead_rates[channel] = (len(channel_leads) / len(channel_convs)) * 100 if len(channel_convs) > 0 else 0\n",
    "        \n",
    "        axes[2].bar(lead_rates.keys(), lead_rates.values(), color=sns.color_palette('husl', len(lead_rates)))\n",
    "        axes[2].set_xlabel('Channel')\n",
    "        axes[2].set_ylabel('Lead Capture Rate (%)')\n",
    "        axes[2].set_title('Lead Conversion by Channel')\n",
    "    else:\n",
    "        axes[2].text(0.5, 0.5, 'No lead data available', ha='center', va='center', transform=axes[2].transAxes)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Insufficient data for channel visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Export Data for External Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV files for external analysis (e.g., BigQuery, Looker, Zapier)\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "export_dir = 'exports'\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Export each dataset\n",
    "exports = {\n",
    "    'tenants': df_tenants,\n",
    "    'conversations': df_conversations,\n",
    "    'messages': df_messages,\n",
    "    'leads': df_leads\n",
    "}\n",
    "\n",
    "print(\"Exporting data to CSV...\")\n",
    "for name, df in exports.items():\n",
    "    if len(df) > 0:\n",
    "        filepath = f\"{export_dir}/{name}_{timestamp}.csv\"\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(f\"  âœ“ {name}: {filepath} ({len(df):,} rows)\")\n",
    "    else:\n",
    "        print(f\"  - {name}: (empty, skipped)\")\n",
    "\n",
    "print(f\"\\nExport complete. Files saved to: {export_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Summary Report\n",
    "print(\"=\" * 60)\n",
    "print(\"           CHATTERCHEETAH DATA ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "# Platform Overview\n",
    "print(\"ðŸ“Š PLATFORM OVERVIEW\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"  Active Tenants: {df_tenants['is_active'].sum() if len(df_tenants) > 0 else 0}\")\n",
    "print(f\"  Total Conversations: {len(df_conversations):,}\")\n",
    "print(f\"  Total Messages: {len(df_messages):,}\")\n",
    "print(f\"  Total Leads: {len(df_leads):,}\")\n",
    "print()\n",
    "\n",
    "# Engagement Metrics\n",
    "if len(df_messages) > 0 and len(df_conversations) > 0:\n",
    "    print(\"ðŸ’¬ ENGAGEMENT METRICS\")\n",
    "    print(\"-\" * 40)\n",
    "    msgs_per_conv = df_messages.groupby('conversation_id').size()\n",
    "    print(f\"  Avg Messages per Conversation: {msgs_per_conv.mean():.1f}\")\n",
    "    if 'duration_minutes' in df_conversations.columns:\n",
    "        print(f\"  Avg Conversation Duration: {df_conversations['duration_minutes'].median():.1f} min\")\n",
    "    print()\n",
    "\n",
    "# Lead Performance\n",
    "if len(df_leads) > 0:\n",
    "    print(\"ðŸŽ¯ LEAD PERFORMANCE\")\n",
    "    print(\"-\" * 40)\n",
    "    capture_rate = (len(df_leads) / len(df_conversations)) * 100 if len(df_conversations) > 0 else 0\n",
    "    print(f\"  Lead Capture Rate: {capture_rate:.1f}%\")\n",
    "    complete_leads = df_leads[df_leads['has_email'] & df_leads['has_phone'] & df_leads['has_name']]\n",
    "    quality_rate = (len(complete_leads) / len(df_leads)) * 100\n",
    "    print(f\"  Complete Lead Rate: {quality_rate:.1f}%\")\n",
    "    print()\n",
    "\n",
    "# Channel Breakdown\n",
    "if len(df_conversations) > 0:\n",
    "    print(\"ðŸ“± CHANNEL BREAKDOWN\")\n",
    "    print(\"-\" * 40)\n",
    "    for channel, count in df_conversations['channel'].value_counts().items():\n",
    "        pct = (count / len(df_conversations)) * 100\n",
    "        print(f\"  {channel}: {count:,} ({pct:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"End of Report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "custom-queries-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Custom Query Section\n",
    "\n",
    "Use this section to run custom SQL queries or pandas operations on the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom-query",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Custom SQL Query\n",
    "# Uncomment and modify as needed\n",
    "\n",
    "# async def run_custom_query(query: str) -> pd.DataFrame:\n",
    "#     \"\"\"Run a custom SQL query and return as DataFrame.\"\"\"\n",
    "#     async with get_db_session() as session:\n",
    "#         result = await session.execute(text(query))\n",
    "#         rows = result.fetchall()\n",
    "#         columns = result.keys()\n",
    "#         return pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "# # Example query\n",
    "# query = \"\"\"\n",
    "# SELECT \n",
    "#     t.name as tenant_name,\n",
    "#     COUNT(DISTINCT c.id) as conversation_count,\n",
    "#     COUNT(m.id) as message_count\n",
    "# FROM tenants t\n",
    "# LEFT JOIN conversations c ON t.id = c.tenant_id\n",
    "# LEFT JOIN messages m ON c.id = m.conversation_id\n",
    "# GROUP BY t.id, t.name\n",
    "# ORDER BY conversation_count DESC\n",
    "# \"\"\"\n",
    "# \n",
    "# df_custom = run_async(run_custom_query(query))\n",
    "# display(df_custom)\n",
    "\n",
    "print(\"Custom query section - uncomment and modify the code above to run custom queries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick data exploration commands\n",
    "# Uncomment as needed\n",
    "\n",
    "# View first few rows of any dataset\n",
    "# df_conversations.head(10)\n",
    "# df_messages.head(10)\n",
    "# df_leads.head(10)\n",
    "\n",
    "# Get column info\n",
    "# df_conversations.info()\n",
    "\n",
    "# Describe numeric columns\n",
    "# df_messages.describe()\n",
    "\n",
    "# Filter examples\n",
    "# df_conversations[df_conversations['channel'] == 'web']\n",
    "# df_leads[df_leads['has_email'] == True]\n",
    "\n",
    "print(\"Data exploration section - uncomment lines above to explore the loaded data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
